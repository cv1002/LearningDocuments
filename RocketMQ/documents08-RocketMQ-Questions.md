# TOC
- [TOC](#toc)
- [MQ 如何快速处理积压的消息](#mq-如何快速处理积压的消息)
  - [消息积压会有什么问题](#消息积压会有什么问题)
  - [怎么处理大量积压的消息](#怎么处理大量积压的消息)

# MQ 如何快速处理积压的消息

## 消息积压会有什么问题
对于RocketMQ和Kafka来说，他们的消息积压能力本身就是很强的，因此短时间的积压是没有太多问题的。但是需要注意，如果消息积压问题一直得不到解决，日志文件过期后，就会删除过期的日志文件，而日志上未消费的消息就会丢失。

对于RabbitMQ来说，classic queue经典队列和quorum queue仲裁队列。如果有大量消息积压，未被消费，就会严重影响性能，需要重点关注。对于stream queue流式队列，整体处理机制与Kafka和RocketMQ类似，对消息积压的承受能力就会比较强。

## 怎么处理大量积压的消息
核心原因是消费速率过低，所以要提升消费速率。如果不能从业务上提升消费者的消费性能，则最直接的方法就是针对处理慢的消费者组，增加更多的消费者实例。但是注意增加消费者实例是否有上限。

对于RabbitMQ来说，如果是经典队列，那么针对同一个Queue的消费者，是按WorkQueue的模式，在多个消费者之间依次分配消息的。所以这时如果消费者消费能力不够，直接增加新的消费者实例即可。这里可以注意不同消费者的消费由于运行环境、或者是处理消息的速率不同的情况，可以优化每个消费者的比重，从而尽量大的发挥不同消费者实例的性能。

对于RocketMQ而言，因为同一个消费者组下的多个消费者需要和Topic下的MessageQueue建立对应关系，而一个MessageQueue只能被一个消费者消费，因此增加的消费者实例最多也只能和Topic下的MessageQueue个数相同。之后再增加也不会提升处理速率了。

因此如果MessageQueue的数目不够多的情况，无法一直增加消费者节点。如果要处理积压的消息，可以创建新的Topic，配置足够多的MessageQueue，如何把消费者实例的Topic转向新的Topic，并紧急上线一组新的消费者，只负责处理旧的Topic中的消息，并转存到新的Topic中。速度明显会比普通消费者处理业务逻辑要快很多。如何再新的Topic上就可以通过增加消费者个数来提高消费速度了。之后再考虑是否需要恢复成正常情况。

> 其实这种思路和RocketMQ内部很多特殊机制的处理方式类似。例如固定级别的延迟消息机制，也是把消息临时转到内部的一个Topic下，处理过后再转回来。

至于Kafka，也可以采用和类似的方式处理。