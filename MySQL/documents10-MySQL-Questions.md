# TOC
- [TOC](#toc)
- [数据库的三范式是什么？](#数据库的三范式是什么)
- [MySQL 支持哪些存储引擎?](#mysql-支持哪些存储引擎)
- [说一下 MySQL 主从复制原理？](#说一下-mysql-主从复制原理)
  - [主从复制优点](#主从复制优点)
  - [主从复制原理](#主从复制原理)
  - [主从复制模式](#主从复制模式)
- [MySQL中一张表有500万数据，100多个字段，请问如何快速把数据查出来](#mysql中一张表有500万数据100多个字段请问如何快速把数据查出来)
  - [Ans1](#ans1)
  - [Ans2](#ans2)
    - [一、 第一要务：优化查询语句和索引 (成本最低，效果最显著)](#一-第一要务优化查询语句和索引-成本最低效果最显著)
    - [二、 数据库设计优化 (需要停机或低峰期操作)](#二-数据库设计优化-需要停机或低峰期操作)
    - [三、 系统架构优化 (成本最高，效果最大)](#三-系统架构优化-成本最高效果最大)
    - [总结与行动建议](#总结与行动建议)
  - [Ans3](#ans3)
    - [💡 综合建议与注意事项](#-综合建议与注意事项)
- [想清理一张表的历史数据，请问 truncate、delete、drop三种方式哪个更好些？](#想清理一张表的历史数据请问-truncatedeletedrop三种方式哪个更好些)

# 数据库的三范式是什么？
- 第一范式：强调的是列的原子性，即数据库表的每一列都是不可分割的原子数据项。
- 第二范式：要求实体的属性完全依赖于主关键字。所谓完全依赖是指不能存在仅依赖主关键字一部分的属性。
- 第三范式：任何非主属性不依赖于其它非主属性。

# MySQL 支持哪些存储引擎?
MySQL 支持多种存储引擎,比如 InnoDB,MyISAM,Memory,Archive 等等

在大多数的情况下,直接选择使用 InnoDB 引擎都是最合适的,InnoDB 也是 MySQL 的默认存储引擎。

MyISAM 和 InnoDB 的区别有哪些：
- InnoDB 支持事务，MyISAM 不支持
- InnoDB 支持外键，而 MyISAM 不支持
- InnoDB 是聚集索引，数据文件是和索引绑在一起的，必须要有主键，通过主键索引效率很高；MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针，主键索引和辅助索引是独立的。
- Innodb 不支持全文索引，而 MyISAM 支持全文索引，查询效率上 MyISAM 要高；
- InnoDB 不保存表的具体行数，MyISAM 用一个变量保存了整个表的行数。
- MyISAM 采用表级锁(table-level locking)；InnoDB 支持行级锁(row-level locking)和表级锁,默认为行级锁。

# 说一下 MySQL 主从复制原理？
- [Reference1](https://www.cnblogs.com/vipstone/p/17934625.html)
- [Reference2](https://learn.lianglianglee.com/%E6%96%87%E7%AB%A0/MySQL%20%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6.md)

## 主从复制优点
主从复制的主要优点有以下几个：

- 高可用性：通过将主数据库的数据复制到一个或多个从数据库，可以在主数据库故障时快速切换到从数据库，以实现系统的高可用性和容错能力，从而保证系统的持续可用性。
- 提高整体性能和吞吐量：通过将读请求分散到多个从服务器上进行处理，从而减轻了主服务器的负载压力，提高数据库系统的整体性能和吞吐量。主服务器主要负责写操作，而从服务器主要负责读操作，从而分担了主服务器的压力。
- 数据备份和恢复：通过主从同步，可以将主服务器上的数据异步复制到从服务器上，从而实现数据备份和灾难恢复的需求。在应对意外数据丢失、灾难恢复或误操作时，可以使用从服务器作为数据的备份源来进行数据恢复。
- 数据分析可以在从库中进行，不影响业务
- 数据库备份时，对业务影响降到最低

## 主从复制原理
MySQL 数据库的主从复制主要是基于 binlog 实现的。

它的主要执行流程如下：

- 主数据库接收到一个写操作（如 INSERT、UPDATE、DELETE）时，会将这个操作记录到 binlog 中，将数据修改的操作按顺序记录下来。
- 从数据库 IO 线程会自动连接主服务，从 binlog 中读取同步数据，记录到中继日志（Relay Log）中。
- 从数据库的 SQL 线程会定期从中继日志中获取同步数据，写入到从数据库中。

## 主从复制模式
MySQL 中主要有以下两种主从复制的模式，分别是异步复制和半同步复制。

- 异步复制：MySQL 主从复制中最常见和默认的模式。在异步复制模式中，主服务器将数据修改操作记录到二进制日志（Binary Log）中，并将日志传输给从服务器。从服务器接收到二进制日志后，会异步地应用这些日志进行数据复制。
  - 优点：它的优点是及时响应给使用者，主服务器不会受到从服务器的影响而等待确认，可以提高主服务器的性能。
  - 缺点：由于是异步复制，可能存在数据传输的延迟，且从服务器上的复制过程是不可靠的。如果主服务器故障，尚未应用到从服务器的数据可能会丢失。
- 半同步复制：半同步复制是 MySQL 主从复制中的一种增强模式。在半同步复制模式中，主服务器将数据修改操作记录到二进制日志，并等待至少一个从服务器确认已接收到并应用了这些日志后才继续执行后续操作。
  - 优点：可以提供更高的数据一致性和可靠性，确保至少一个从服务器与主服务器保持同步。如果主服务器故障，已经确认接收并应用到从服务器的数据不会丢失。
  - 缺点：由于半同步复制需要等待从服务器的确认，因此相对于异步复制，会增加一定的延迟，可能会影响主服务器的性能。

如果对数据一致性和可靠性要求较高，可以考虑使用半同步复制；如果对延迟和主服务器性能要求较高，可以继续使用异步复制，根据实际需求调整复制模式。

# MySQL中一张表有500万数据，100多个字段，请问如何快速把数据查出来

## Ans1

- 只选择必要的字段
- 使用索引
  - 确保查询的列上有适当的索引
  - 使用覆盖索引可以避免回表查询 **注意：覆盖索引指索引包含所有查询的字段**
- 分页查询
  - 如果需要处理大量数据，考虑使用分页查询来分批获取数据
  - **注意** 对于大偏移量的分页，limit/offset可能导致性能问题，可以考虑使用主键或者唯一索引之类的方式优化 Ref:https://zhuanlan.zhihu.com/p/15268867931
- 优化查询条件
  - 使用高效的查询条件，避免在WHERE子句中使用函数或计算
  - 尽量使用等值查询而不是范围查询
- 数据库配置优化
  - 调整数据库配置参数，如innodb_buffer_pool_size，以便更好的利用内存
  - 确保服务器有足够的内存和CPU资源
- 分区表
  - 对于非常大的表可以考虑使用表分区，将数据按照某个字段（如日期）分割成多个物理部分
- 缓存机制
  - 使用缓存机制如Redis来存储常用查询的结果，减少数据库的负载
- 分析执行计划
  - 使用EXPLAIN命令分析查询的执行计划，找出潜在的性能瓶颈
- 批量处理
  - 如果需要大量数据进行批量处理，考虑使用批量操作而不是逐行处理

## Ans2
您好！500万数据、100多个字段的表查询优化，确实是一个典型的性能挑战。要快速查出来，需要从**数据库设计、SQL编写、架构优化**三个层面系统性地进行优化。

快速查出来有两种常见场景：
1.  **前端分页展示**：每次只查几十条，追求毫秒级响应。
2.  **数据导出或分析**：需要一次性或分批获取大量甚至全量数据，追求总体耗时最短。

针对您的情况，以下是详细的优化方案，从最简单有效的开始：

---

### 一、 第一要务：优化查询语句和索引 (成本最低，效果最显著)

这是最立竿见影的方法，95%的慢查询可以通过这里解决。

1.  **严禁 `SELECT *`**
    *   **问题**：100多个字段，数据量非常大。网络传输和内存占用会极高。
    *   **优化**：严格只查询**需要的字段**。例如：
        ```sql
        -- 非常慢
        SELECT * FROM huge_table WHERE condition;

        -- 快很多倍
        SELECT id, name, create_time FROM huge_table WHERE condition;
        ```

2.  **高效的分页策略 - 深度分页优化**
    *   **问题**：使用 `LIMIT 5000000, 20` 时，MySQL需要先读取5000020条数据，然后扔掉前5000000条，非常慢。
    *   **优化**：使用**基于索引和主键的"书签"分页**。
        ```sql
        -- 传统慢分页
        SELECT * FROM table ORDER BY create_time DESC LIMIT 5000000, 20;

        -- 优化后的快分页 (假设上一次查询的最后一条create_time是 '2023-10-01 12:00:00')
        SELECT * FROM table 
        WHERE create_time < '2023-10-01 12:00:00' 
        ORDER BY create_time DESC 
        LIMIT 20;
        ```
        *   前提是 `ORDER BY` 的字段（如 `create_time`）上有索引。

3.  **添加合适的索引**
    *   **原则**：在 `WHERE` 子句和 `ORDER BY` 子句频繁使用的字段上创建索引。
    *   **注意**：
        *   索引不是越多越好，会影响写操作（INSERT/UPDATE/DELETE）的速度。
        *   对于100多个字段的表，优先为高筛选性的字段（如状态、时间、类别ID等）建索引。
        *   考虑使用**复合索引**（联合索引）来覆盖多个查询条件。

4.  **避免复杂的JOIN和子查询**
    *   如果可能，将复杂的查询拆分成多个简单查询，在应用层处理。MySQL对复杂JOIN的优化有时并不好。

---

### 二、 数据库设计优化 (需要停机或低峰期操作)

1.  **垂直分表**
    *   **思路**：这是针对100多个字段最有效的设计优化。将访问频率高的字段（20-30个）和访问频率低的大字段（如TEXT/BLOB类型、备注、详情等）拆分成两张表。
    *   **做法**：
        *   **主表**：`main_table` (id, 经常查询和更新的字段1, 字段2, ...)
        *   **扩展表**：`extend_table` (id, 主表_id, 不常用的大字段1, 大字段2, ...)
    *   **效果**：查询主表时，数据量更小，IO效率更高。需要大字段时再通过JOIN关联查询。

2.  **分区表**
    *   **思路**：根据某个规则（如时间范围）将一张表的数据在物理上存储到不同的文件里，但逻辑上还是一张表。
    *   **适用场景**：非常适合按时间进行范围查询的场景（例如，经常查询最近三个月的数据）。查询时，MySQL可以只扫描目标分区，大大减少数据扫描量。
    *   **注意**：分区键选择很重要，设计不好会导致性能下降。而且分区表的管理和维护有一定复杂度。

3.  **使用更优的数据类型**
    *   检查字段类型，用最小的数据类型来存储数据。例如：
        *   用 `INT` 而不是 `BIGINT`（如果数值范围够）。
        *   用 `VARCHAR(255)` 而不是 `TEXT`（如果长度可控）。
        *   用 `TIMESTAMP` 而不是 `DATETIME`（如果时间范围1970-2038年满足要求）。

---

### 三、 系统架构优化 (成本最高，效果最大)

当单机MySQL优化到极致后仍无法满足需求时，考虑架构升级。

1.  **读写分离**
    *   **思路**：主数据库（Master）负责处理写操作，多个从数据库（Slave）负责处理读操作。应用端将读写请求分发到不同的数据库。
    *   **效果**：极大地提升查询性能，缓解主库压力。非常适合读远大于写的场景。

2.  **使用缓存**
    *   **思路**：引入Redis、Memcached等缓存中间件，将频繁读取且不常变的热点数据存入缓存。
    *   **效果**：查询请求首先访问缓存，未命中再去查数据库，极大减轻数据库压力并提升响应速度。

3.  **数据异构与ES/Solr搜索**
    *   **思路**：如果查询条件非常复杂多变（例如多个字段任意组合筛选），MySQL的索引会很难设计。
    *   **做法**：将数据同步到Elasticsearch或Solr这类专业的搜索引擎中，它们擅长海量数据的复杂查询和全文检索。

4.  **水平分库分表**
    *   **思路**：这是终极方案。将一张表的数据拆分到多个数据库的多个表中（例如，按用户ID哈希取模）。
    *   **效果**：解决了单表数据量过大的根本问题。
    *   **代价**：技术复杂度极高，会带来分布式事务、跨库JOIN、全局主键生成等一系列挑战。**除非迫不得已，否则不要轻易使用。**

---

### 总结与行动建议

对于您的500万数据、100多个字段的表，建议按以下顺序操作：

1.  **立即检查并优化所有SQL语句**：确保没有 `SELECT *`，使用了高效分页，并且所有核心查询都已被合适的索引覆盖。**这一步能解决大部分问题。**
2.  **评估垂直分表的可能性**：分析字段使用频率，将大字段拆分到扩展表。这对性能提升会非常明显。
3.  **考虑引入缓存**：将最热点的数据（如用户信息、配置信息）缓存到Redis中。
4.  **如果数据持续快速增长**，评估读写分离方案，这是性价比很高的扩展方式。
5.  **最后的手段**：如果以上所有方案都无法满足未来需求，再考虑水平分库分表这个"大杀器"。

**数据导出场景特别建议**：
如果需要快速导出全部数据，不要用一条`SELECT`，而是用程序**分批次查询和写入**。
```python
# 伪代码示例
last_id = 0
while True:
    batch = sql.execute("SELECT * FROM table WHERE id > ? ORDER BY id LIMIT 10000", (last_id,))
    if not batch:
        break
    # 处理这一批10000条数据
    save_to_csv(batch)
    last_id = batch[-1].id # 记录这批数据的最大ID
```
这种方式对数据库压力小，且不容易超时和内存溢出。

## Ans3
### 💡 综合建议与注意事项

1.  理解你的查询：优化前，先用 EXPLAIN 分析你的关键查询语句，了解其执行计划（是否使用索引、是否全表扫描等）。关注 type（访问类型）、key（使用的索引）、rows（预估扫描行数）和 Extra（额外信息）这些字段。
2.  索引是一把双刃剑：虽然能极大加速查询，但会降低写操作（INSERT, UPDATE, DELETE）的速度并占用额外空间。不要过度索引。
3.  优先考虑简单的优化：通常，优化查询语句和添加索引是性价比最高且最容易实施的起点。
4.  架构调整需谨慎：像分库分表这样的操作，虽然效果显著，但会对应用逻辑带来巨大复杂性和维护成本。只有在单表优化手段难以满足需求时才应考虑。
5.  定期维护：对大型表定期执行 OPTIMIZE TABLE 来整理碎片，使用 ANALYZE TABLE 来更新统计信息，帮助优化器做出更好的决策。

# 想清理一张表的历史数据，请问 truncate、delete、drop三种方式哪个更好些？
- truncate 清理表，但表结构保留
- delete   删除部份数据
- drop     整个表都不要了

